"""
system/vtuber_system_adaptive.py ‚Äî —è–¥—Ä–æ VTuber AI —Å –∞–¥–∞–ø—Ç–∞—Ü–∏–µ–π –ª–∏—á–Ω–æ—Å—Ç–∏ (–≤—Å—ë –≤ –æ–¥–Ω–æ–º —Ñ–∞–π–ª–µ)
–ë–∞–∑–∏—Ä—É–µ—Ç—Å—è –Ω–∞ —Ç–≤–æ—ë–º –∞–∫—Ç—É–∞–ª—å–Ω–æ–º vtuber_system.py, –¥–æ–±–∞–≤–ª–µ–Ω—ã:
- –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π –∫–ª–∞—Å—Å AdaptivePersonality (–º—è–≥–∫–æ–µ —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏–µ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤–µ—Å–æ–≤)
- –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è self.adaptive –≤ __init__
- –≤—ã–∑–æ–≤ await self.adaptive.analyze_and_update(user_text, reply) –≤ —Ü–∏–∫–ª–µ –¥–∏–∞–ª–æ–≥–∞
- —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã CUDA-–Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏ —á—Ç–µ–Ω–∏–µ config.json (devices: llm/cuda:0, stt/tts ‚Üí cuda:1)
"""

from __future__ import annotations

import asyncio
import contextlib
import functools
import logging
import re
import signal
import sys
from dataclasses import dataclass
from datetime import datetime
from typing import Optional

import sounddevice as sd  # –¥–ª—è –ø–µ—Ä–µ—Ö–≤–∞—Ç–∞ sd.PortAudioError

# --- –ò–º–ø–æ—Ä—Ç—ã –ø–æ–¥—Å–∏—Å—Ç–µ–º (–∫–∞–∫ –≤ —Ç–≤–æ—ë–º –ø—Ä–æ–µ–∫—Ç–µ) ---
from core.config import VTuberConfig, load_config
from core.mood import MoodManager
from core.memory import HybridMemory
from avatar.personalization import (
    PersonalizationManager,
    apply_personalized_prompt,
    log_after_dialog,
)
from llm.router import HybridOllamaRouter
from llm.ollama_client import OptimizedOllamaClient
from audio.tts import TTS
# prefer local upgraded STT, fallback to original
try:
    from stt import WhisperSTT  # upgraded async VAD+ASR
except Exception:
    from audio.stt import WhisperSTT
from avatar.osc import MultiTargetOSCController

# --- –ò–º–ø–æ—Ä—Ç —ç–º–æ—Ü–∏–π (fallback –µ—Å–ª–∏ –º–æ–¥—É–ª—å –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω) ---
try:
    from avatar.emotion import EmotionType, BLENDMAP
except Exception:
    class EmotionType:
        HAPPY = type("E", (), {"value": "Joy"})
        SAD = type("E", (), {"value": "Sad"})
        ANGRY = type("E", (), {"value": "Angry"})
        SURPRISED = type("E", (), {"value": "Surprised"})
        NEUTRAL = type("E", (), {"value": "Neutral"})
    BLENDMAP = {
        EmotionType.HAPPY: "Joy",
        EmotionType.SAD: "Sad",
        EmotionType.ANGRY: "Angry",
        EmotionType.SURPRISED: "Surprised",
        EmotionType.NEUTRAL: "Neutral",
    }

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è ---
logger = logging.getLogger("VTuberSystem")
if not logger.handlers:
    _h = logging.StreamHandler()
    _h.setFormatter(logging.Formatter("[%(asctime)s] %(levelname)s: %(message)s"))
    logger.addHandler(_h)
logger.setLevel(logging.INFO)


# ======================================================================
#           –í–°–¢–†–û–ï–ù–ù–´–ô –ú–û–î–£–õ–¨ –ú–Ø–ì–ö–û–ô –ê–î–ê–ü–¢–ê–¶–ò–ò –õ–ò–ß–ù–û–°–¢–ò (RU)
# ======================================================================
class AdaptivePersonality:
    """
    –ú—è–≥–∫–∞—è –∞–¥–∞–ø—Ç–∞—Ü–∏—è –ª–∏—á–Ω–æ—Å—Ç–∏ AI –±–µ–∑ –æ–±—É—á–µ–Ω–∏—è –≤–µ—Å–æ–≤ –º–æ–¥–µ–ª–∏.
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø–æ—Å–ª–µ–¥–Ω—é—é —Ä–µ–ø–ª–∏–∫—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ –æ—Ç–≤–µ—Ç AI,
    –æ–±–Ω–æ–≤–ª—è–µ—Ç –ø—Ä–æ—Ñ–∏–ª—å (tone/mood/response_style) –≤ PersonalizationManager.
    """

    def __init__(self, personalization: PersonalizationManager):
        self.personalization = personalization

    async def analyze_and_update(self, user_text: str, model_reply: str) -> None:
        mood = self._detect_mood(user_text, model_reply)
        tone = self._detect_tone(user_text, model_reply)
        style = self._detect_style(user_text, model_reply)

        changed = False
        profile = getattr(self.personalization, "profile", {}) or {}

        if mood and profile.get("mood") != mood:
            profile["mood"] = mood
            changed = True

        if tone and profile.get("tone") != tone:
            profile["tone"] = tone
            changed = True

        if style and profile.get("response_style") != style:
            profile["response_style"] = style
            changed = True

        if changed:
            profile["last_update"] = datetime.now().isoformat(timespec="seconds")
            # —Å–æ—Ö—Ä–∞–Ω—è–µ–º —á–µ—Ä–µ–∑ –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏—é (—É —Ç–µ–±—è —É–∂–µ –µ—Å—Ç—å –º–µ—Ç–æ–¥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è)
            try:
                self.personalization.profile = profile
                if hasattr(self.personalization, "save_profile"):
                    self.personalization.save_profile()
            except Exception as e:
                logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏—é: {e}")
            else:
                logger.info(f"üß† Personality adapted ‚Üí mood={profile.get('mood')}, tone={profile.get('tone')}, style={profile.get('response_style')}")

    # --- –ü—Ä–æ—Å—Ç–µ–π—à–∏–µ —ç–≤—Ä–∏—Å—Ç–∏–∫–∏ –Ω–∞ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤–∞—Ö (–º–æ–∂–Ω–æ –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ —Ç–æ–Ω–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑) ---
    def _detect_mood(self, user_text: str, reply: str) -> Optional[str]:
        text = f"{user_text} {reply}".lower()
        if re.search(r"(–ø–ª–æ—Ö–æ|–≥—Ä—É—Å—Ç–Ω|–æ–¥–∏–Ω–æ–∫|—É—Å—Ç–∞–ª|—Ç–æ—Å–∫–∞|–ø–µ—á–∞–ª—å|—Å–ª–æ–∂–Ω–æ)", text):
            return "supportive"      # –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–∏–π
        if re.search(r"(–≤–µ—Å–µ–ª|—É—Ä–∞|—Å–º–µ—à–Ω|—Ö–∞—Ö–∞|—Ä–∞–¥|–∫–ª–∞—Å—Å|—Å—É–ø–µ—Ä)", text):
            return "cheerful"        # –≤–µ—Å—ë–ª—ã–π
        if re.search(r"(–∑–ª—é—Å—å|—Ä–∞–∑–¥—Ä–∞–∂|–±–µ—Å–∏—Ç|–Ω–µ–Ω–∞–≤–∏–∂—É|–∑–ª–æ–π)", text):
            return "calm"            # —Å–ø–æ–∫–æ–π–Ω—ã–π (—É—Å–ø–æ–∫–∞–∏–≤–∞—é—â–∏–π)
        if re.search(r"(–ª—é–±–ª—é|—Å–ø–∞—Å–∏–±–æ|–±–ª–∞–≥–æ–¥–∞—Ä—é|–±–ª–∞–≥–æ–¥–∞—Ä–µ–Ω)", text):
            return "empathetic"      # —ç–º–ø–∞—Ç–∏—á–Ω—ã–π
        return None

    def _detect_tone(self, user_text: str, reply: str) -> Optional[str]:
        text = f"{user_text} {reply}".lower()
        if re.search(r"(–∫–æ—Ä–æ—Ç–∫–æ|–ø–æ –¥–µ–ª—É|–±–µ–∑ –≤–æ–¥—ã|–Ω–µ —Ä–∞—Å—Ç—è–≥–∏–≤–∞–π)", text):
            return "concise"
        if re.search(r"(—Ä–∞—Å—Å–∫–∞–∂–∏ –ø–æ–¥—Ä–æ–±–Ω–µ–µ|–æ–±—ä—è—Å–Ω–∏|–ø–æ—è—Å–Ω–∏|—Ä–∞–∑–≤–µ—Ä–Ω—É—Ç–æ)", text):
            return "detailed"
        if re.search(r"(—à—É—Ç–∏|–∞–Ω–µ–∫–¥–æ—Ç|—Å–º–µ—à–Ω|–∏–≥—Ä–∏–≤–æ)", text):
            return "playful"
        if re.search(r"(–º–µ–¥–ª–µ–Ω–Ω–æ|—Å–ø–æ–∫–æ–π–Ω–æ|—Ç–∏—à–µ|–Ω–µ —Å–ø–µ—à–∏)", text):
            return "calm"
        return None

    def _detect_style(self, user_text: str, reply: str) -> Optional[str]:
        text = f"{user_text} {reply}".lower()
        if re.search(r"(—Å–ø–∏—Å–∫–æ–º|–±—É–ª–ª–µ—Ç—ã|–±—É–ª–ª–µ—Ç–∞–º–∏|–ø–æ –ø—É–Ω–∫—Ç–∞–º)", text):
            return "bulleted"
        if re.search(r"(–ø—Ä–∏–º–µ—Ä|–ø—Ä–∏–º–µ—Ä–æ–º|–∞–Ω–∞–ª–æ–≥–∏—è|—Å—Ä–∞–≤–Ω–µ–Ω–∏–µ)", text):
            return "with_examples"
        return None


# ======================================================================
#                       –û–°–ù–û–í–ù–û–ô –ö–õ–ê–°–° –°–ò–°–¢–ï–ú–´
# ======================================================================
class RealtimeVTuberSystem:
    def __init__(
        self,
        config: Optional[VTuberConfig] = None,
        enable_unity: bool = True,
        install_signal_handlers: bool = True,
    ):
        """–û—Å–Ω–æ–≤–Ω–æ–π –∫–æ–Ω—Ç—Ä–æ–ª–ª–µ—Ä VTuber-—Å–∏—Å—Ç–µ–º—ã.
        install_signal_handlers ‚Äî –µ—Å–ª–∏ False, –Ω–µ –±—É–¥–µ—Ç –ª–æ–≤–∏—Ç—å Ctrl+C (–¥–ª—è Unity, —Ç–µ—Å—Ç–æ–≤ –∏ Jupyter).
        """
        # --- –ê–≤—Ç–æ–æ—Ç–∫–ª—é—á–µ–Ω–∏–µ —Å–∏–≥–Ω–∞–ª–æ–≤, –µ—Å–ª–∏ —Å—Ä–µ–¥–∞ –Ω–µ —Ç–µ—Ä–º–∏–Ω–∞–ª—å–Ω–∞—è ---
        if not sys.stdout.isatty():
            install_signal_handlers = False

        self.config = config or VTuberConfig()
        self.mood = MoodManager()
        self.memory: Optional[HybridMemory] = None
        self.personalization = PersonalizationManager()
        self.install_signal_handlers = install_signal_handlers

        # ‚úÖ –¥–æ–±–∞–≤–ª–µ–Ω–æ: –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–≥–æ –ø–æ–≤–µ–¥–µ–Ω–∏—è
        self.adaptive = AdaptivePersonality(self.personalization)

        # --- –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤ –¥–ª—è STT/TTS (—á–µ—Ä–µ–∑ config.json —Å fallback) ---
        self.stt_device = "cpu"
        self.tts_device = "cpu"
        try:
            import torch
            try:
                # —á–∏—Ç–∞–µ–º –∫–æ–Ω—Ñ–∏–≥ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω–æ (–µ—Å–ª–∏ –∑–∞–¥–∞–Ω–æ)
                cfg = load_config()
                devices_cfg = cfg.get("devices", {})
            except Exception:
                devices_cfg = {}

            stt_device = devices_cfg.get("stt") or devices_cfg.get("audio")
            tts_device = devices_cfg.get("tts") or devices_cfg.get("audio")

            # –µ—Å–ª–∏ –≤ –∫–æ–Ω—Ñ–∏–≥–µ –Ω–µ —É–∫–∞–∑–∞–Ω–æ ‚Äî –∞–≤—Ç–æ–¥–µ—Ç–µ–∫—Ç
            if not stt_device or not tts_device:
                if torch.cuda.is_available():
                    gpu_count = torch.cuda.device_count()
                    logger.info(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ GPU: {gpu_count} —à—Ç.")
                    stt_device = stt_device or "cuda:0"
                    tts_device = tts_device or ("cuda:1" if gpu_count > 1 else "cuda:0")
                else:
                    logger.warning("CUDA –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º CPU")
                    stt_device = "cpu"
                    tts_device = "cpu"
            else:
                logger.info(f"–ó–∞–¥–∞–Ω–æ –≤ –∫–æ–Ω—Ñ–∏–≥–µ: STT={stt_device}, TTS={tts_device}")
        except ImportError:
            logger.warning("PyTorch –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º CPU")
            stt_device = "cpu"
            tts_device = "cpu"

        self.stt_device = stt_device
        self.tts_device = tts_device

        # --- –ú–æ–∑–≥ (LLM —Ä–æ—É—Ç–µ—Ä) ---
        try:
            ollama_client = OptimizedOllamaClient()
            self.ollama_client = ollama_client
            self.router = HybridOllamaRouter(
                ollama=ollama_client,
                fast_model=self.config.fast_model,
                smart_model=self.config.smart_model,
            )
            logger.info(f"Router –≥–æ—Ç–æ–≤: fast={self.config.fast_model}, smart={self.config.smart_model}")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ LLM —Ä–æ—É—Ç–µ—Ä–∞: {e}", exc_info=True)
            raise RuntimeError("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å LLM —Å–∏—Å—Ç–µ–º—É") from e

        # --- –ê—É–¥–∏–æ ---
        try:
            self.tts = TTS(
                model="cosyvoice-2",
                speaker="female",
                style="soft",
                language="ru",
                device=self.tts_device,
            )
            cfg = {}
            try:
                cfg = load_config()
            except Exception:
                cfg = {}
            stt_cfg = cfg.get("stt", {})
            self.stt = WhisperSTT(
                model_size=stt_cfg.get("model_size", "small"),
                device=self.stt_device,
                compute_type=stt_cfg.get("compute_type", "float16"),
                beam_size=stt_cfg.get("beam_size", 1),
                sample_rate=stt_cfg.get("sample_rate", 16000),
                chunk_sec=stt_cfg.get("chunk_sec", 0.5),
                vad_backend=stt_cfg.get("vad_backend", "silero_onnx"),
                silero_model_path=stt_cfg.get("silero_model_path"),
                speech_threshold=stt_cfg.get("speech_threshold", 0.55),
                silence_threshold=stt_cfg.get("silence_threshold", 0.45),
                min_speech_ms=stt_cfg.get("min_speech_ms", 200),
                min_silence_ms=stt_cfg.get("min_silence_ms", 500),
            )
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∞—É–¥–∏–æ –º–æ–¥—É–ª–µ–π: {e}", exc_info=True)
            raise RuntimeError("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∞—É–¥–∏–æ –ø–æ–¥—Å–∏—Å—Ç–µ–º—É") from e

        # --- –ê–≤–∞—Ç–∞—Ä (OSC) ---
        self.avatar = MultiTargetOSCController(enable_unity=enable_unity)

        # --- –°–ª—É–∂–µ–±–Ω—ã–µ —Ñ–ª–∞–≥–∏ ---
        self._running = False
        self._stop_lock = asyncio.Lock()
        self._signal_handlers_installed = False

        logger.info(f"‚úÖ RealtimeVTuberSystem –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ (STT: {self.stt_device}, TTS: {self.tts_device})")

    # ------------------------------------------------------------------
    async def start(self) -> None:
        if self._running:
            logger.warning("VTuber —É–∂–µ –∑–∞–ø—É—â–µ–Ω.")
            return

        self.memory = HybridMemory()
        await self.memory.aopen()
        self._running = True

        # --- –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤ —Å–∏–≥–Ω–∞–ª–æ–≤ ---
        if self.install_signal_handlers and not self._signal_handlers_installed:
            loop = asyncio.get_running_loop()

            def _graceful_stop(sig: signal.Signals):
                logger.warning(f"–ü–æ–ª—É—á–µ–Ω —Å–∏–≥–Ω–∞–ª {sig.name} ‚Äî –Ω–∞—á–∏–Ω–∞–µ–º –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ...")
                asyncio.create_task(self.stop())

            for sig in (signal.SIGINT, signal.SIGTERM):
                with contextlib.suppress(NotImplementedError):
                    loop.add_signal_handler(sig, functools.partial(_graceful_stop, sig))

            self._signal_handlers_installed = True

        logger.info("VTuber –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ (–Ω–∞–∂–º–∏ Ctrl+C –¥–ª—è –≤—ã—Ö–æ–¥–∞).")

    # ------------------------------------------------------------------
    async def stop(self) -> None:
        async with self._stop_lock:
            if not self._running:
                return
            self._running = False

            logger.info("–û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º VTuber...")

            with contextlib.suppress(Exception):
                await self.tts.stop()
            with contextlib.suppress(Exception):
                await self.avatar.shutdown()
            with contextlib.suppress(Exception):
                if self.memory:
                    await self.memory.aclose()
            with contextlib.suppress(Exception):
                if getattr(self, 'ollama_client', None):
                    await self.ollama_client.close()

            logger.info("VTuber –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –∑–∞–≤–µ—Ä—à—ë–Ω.")

    # ------------------------------------------------------------------
    async def run_dialogue(self) -> None:
        if not self._running:
            logger.error("–°–∏—Å—Ç–µ–º–∞ –Ω–µ –∑–∞–ø—É—â–µ–Ω–∞. –°–Ω–∞—á–∞–ª–∞ –≤—ã–∑–æ–≤–∏ await start().")
            return

        error_count = 0

        while self._running:
            try:
                user_text = await self.stt.listen()
                if not user_text:
                    await asyncio.sleep(0.2)
                    continue
                await self.memory.add_turn("user", user_text)

                context = await self.memory.context(user_text)

                base_prompt = "–¢—ã ‚Äî –≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã–π VTuber-–∫–æ–º–ø–∞–Ω—å–æ–Ω. –û–±—â–∞–π—Å—è –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ –∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–π –∫–æ–Ω—Ç–∞–∫—Ç."
                personalized_prompt = await apply_personalized_prompt(base_prompt, username="guest", platform="voice")

                reply, emotion_name = await self.router.generate_reply(
                    user_text, context=context, system_prompt=personalized_prompt
                )

                # ‚úÖ –∞–¥–∞–ø—Ç–∞—Ü–∏—è –ª–∏—á–Ω–æ—Å—Ç–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∏–∞–ª–æ–≥–∞ (–¥–æ TTS)
                await self.adaptive.analyze_and_update(user_text, reply)

                await self.memory.add_turn("assistant", reply)

                await self.tts.speak(reply, emotion=emotion_name)
                await log_after_dialog("guest", user_text, reply, emotion_name)

                if hasattr(self.avatar, "set_emotion"):
                    await self.avatar.set_emotion(emotion_name or "neutral")

                error_count = 0

            except asyncio.CancelledError:
                break
            except sd.PortAudioError as e:
                logger.error(f"–ê—É–¥–∏–æ-–æ—à–∏–±–∫–∞: {e}")
                error_count += 1
            except Exception as e:
                logger.exception(f"–û—à–∏–±–∫–∞ –≤ —Ü–∏–∫–ª–µ –¥–∏–∞–ª–æ–≥–∞: {e}")
                error_count += 1

            if error_count > 3:
                logger.warning("‚ö†Ô∏è WhisperSTT –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –ø–æ–≤—Ç–æ—Ä —á–µ—Ä–µ–∑ 3 —Å–µ–∫—É–Ω–¥—ã")
                await asyncio.sleep(3)
                error_count = 0

        logger.info("–í—ã—Ö–æ–¥ –∏–∑ —Ü–∏–∫–ª–∞ –¥–∏–∞–ª–æ–≥–∞.")


# ======================================================================
# –¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞ (—Ä—É—á–Ω–æ–π –∑–∞–ø—É—Å–∫)
# ======================================================================
if __name__ == "__main__":
    async def main():
        vtuber = RealtimeVTuberSystem()
        await vtuber.start()
        try:
            await vtuber.run_dialogue()
        finally:
            await vtuber.stop()

    asyncio.run(main())
