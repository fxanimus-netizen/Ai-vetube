"""
system/vtuber_system_adaptive.py ‚Äî —è–¥—Ä–æ VTuber AI —Å –∞–¥–∞–ø—Ç–∞—Ü–∏–µ–π –ª–∏—á–Ω–æ—Å—Ç–∏ (–≤—Å—ë –≤ –æ–¥–Ω–æ–º —Ñ–∞–π–ª–µ)
–ë–∞–∑–∏—Ä—É–µ—Ç—Å—è –Ω–∞ —Ç–≤–æ—ë–º –∞–∫—Ç—É–∞–ª—å–Ω–æ–º vtuber_system.py, –¥–æ–±–∞–≤–ª–µ–Ω—ã:
- –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π –∫–ª–∞—Å—Å AdaptivePersonality (–º—è–≥–∫–æ–µ —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏–µ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤–µ—Å–æ–≤)
- –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è self.adaptive –≤ __init__
- –≤—ã–∑–æ–≤ await self.adaptive.analyze_and_update(user_text, reply) –≤ —Ü–∏–∫–ª–µ –¥–∏–∞–ª–æ–≥–∞
- —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã CUDA-–Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏ —á—Ç–µ–Ω–∏–µ config.json (devices: llm/cuda:0, stt/tts ‚Üí cuda:1)

–í–ï–†–°–ò–Ø: 2.0 (—É–ª—É—á—à–µ–Ω–Ω–∞—è, 2025)
–ò–ó–ú–ï–ù–ï–ù–ò–Ø:
- –î–æ–±–∞–≤–ª–µ–Ω timeout –¥–ª—è STT (30 —Å–µ–∫)
- –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω —Ä–∞–∑–º–µ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (10+30 –≤–º–µ—Å—Ç–æ 20+100)
- –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π –∑–∞–ø—É—Å–∫ TTS –∏ –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ (-200ms latency)
- –í–∞–ª–∏–¥–∞—Ü–∏—è —ç–º–æ—Ü–∏–π
- –£–ª—É—á—à–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫
- –û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏ –≤ —Ü–∏–∫–ª–µ
- Windows-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–µ signal handlers
"""

from __future__ import annotations

import asyncio
import contextlib
import functools
import logging
import platform
import re
import signal
import sys
from dataclasses import dataclass
from datetime import datetime
from typing import Optional

import sounddevice as sd  # –¥–ª—è –ø–µ—Ä–µ—Ö–≤–∞—Ç–∞ sd.PortAudioError

# --- –ò–º–ø–æ—Ä—Ç—ã –ø–æ–¥—Å–∏—Å—Ç–µ–º (–∫–∞–∫ –≤ —Ç–≤–æ—ë–º –ø—Ä–æ–µ–∫—Ç–µ) ---
from core.config import VTuberConfig, load_config
from core.mood import MoodManager
from core.memory import HybridMemory
from avatar.personalization import (
    PersonalizationManager,
    apply_personalized_prompt,
    log_after_dialog,
)
from llm.router import HybridOllamaRouter
from llm.ollama_client import OptimizedOllamaClient
from audio.tts import TTS
# prefer local upgraded STT, fallback to original
try:
    from stt import WhisperSTT  # upgraded async VAD+ASR
except Exception:
    from audio.stt import WhisperSTT
from avatar.osc import MultiTargetOSCController

# --- –ò–º–ø–æ—Ä—Ç —ç–º–æ—Ü–∏–π (fallback –µ—Å–ª–∏ –º–æ–¥—É–ª—å –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω) ---
try:
    from avatar.emotion import EmotionType, BLENDMAP
except Exception:
    class EmotionType:
        HAPPY = type("E", (), {"value": "Joy"})
        SAD = type("E", (), {"value": "Sad"})
        ANGRY = type("E", (), {"value": "Angry"})
        SURPRISED = type("E", (), {"value": "Surprised"})
        NEUTRAL = type("E", (), {"value": "Neutral"})
    BLENDMAP = {
        EmotionType.HAPPY: "Joy",
        EmotionType.SAD: "Sad",
        EmotionType.ANGRY: "Angry",
        EmotionType.SURPRISED: "Surprised",
        EmotionType.NEUTRAL: "Neutral",
    }

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è ---
logger = logging.getLogger("VTuberSystem")
if not logger.handlers:
    _h = logging.StreamHandler()
    _h.setFormatter(logging.Formatter("[%(asctime)s] %(levelname)s: %(message)s"))
    logger.addHandler(_h)
logger.setLevel(logging.INFO)


# ======================================================================
#           –í–°–¢–†–û–ï–ù–ù–´–ô –ú–û–î–£–õ–¨ –ú–Ø–ì–ö–û–ô –ê–î–ê–ü–¢–ê–¶–ò–ò –õ–ò–ß–ù–û–°–¢–ò (RU)
# ======================================================================
class AdaptivePersonality:
    """
    –ú—è–≥–∫–∞—è –∞–¥–∞–ø—Ç–∞—Ü–∏—è –ª–∏—á–Ω–æ—Å—Ç–∏ AI –±–µ–∑ –æ–±—É—á–µ–Ω–∏—è –≤–µ—Å–æ–≤ –º–æ–¥–µ–ª–∏.
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø–æ—Å–ª–µ–¥–Ω—é—é —Ä–µ–ø–ª–∏–∫—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ –æ—Ç–≤–µ—Ç AI,
    –æ–±–Ω–æ–≤–ª—è–µ—Ç –ø—Ä–æ—Ñ–∏–ª—å (tone/mood/response_style) –≤ PersonalizationManager.
    """

    def __init__(self, personalization: PersonalizationManager):
        self.personalization = personalization

    async def analyze_and_update(self, user_text: str, model_reply: str) -> None:
        mood = self._detect_mood(user_text, model_reply)
        tone = self._detect_tone(user_text, model_reply)
        style = self._detect_style(user_text, model_reply)

        changed = False
        profile = getattr(self.personalization, "profile", {}) or {}

        if mood and profile.get("mood") != mood:
            profile["mood"] = mood
            changed = True

        if tone and profile.get("tone") != tone:
            profile["tone"] = tone
            changed = True

        if style and profile.get("response_style") != style:
            profile["response_style"] = style
            changed = True

        if changed:
            profile["last_update"] = datetime.now().isoformat(timespec="seconds")
            # —Å–æ—Ö—Ä–∞–Ω—è–µ–º —á–µ—Ä–µ–∑ –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏—é (—É —Ç–µ–±—è —É–∂–µ –µ—Å—Ç—å –º–µ—Ç–æ–¥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è)
            try:
                self.personalization.profile = profile
                if hasattr(self.personalization, "save_profile"):
                    self.personalization.save_profile()
            except Exception as e:
                logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏—é: {e}")
            else:
                logger.info(f"üß† Personality adapted ‚Üí mood={profile.get('mood')}, tone={profile.get('tone')}, style={profile.get('response_style')}")

    # --- –ü—Ä–æ—Å—Ç–µ–π—à–∏–µ —ç–≤—Ä–∏—Å—Ç–∏–∫–∏ –Ω–∞ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤–∞—Ö (–º–æ–∂–Ω–æ –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ —Ç–æ–Ω–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑) ---
    def _detect_mood(self, user_text: str, reply: str) -> Optional[str]:
        text = f"{user_text} {reply}".lower()
        if re.search(r"(–ø–ª–æ—Ö–æ|–≥—Ä—É—Å—Ç–Ω|–æ–¥–∏–Ω–æ–∫|—É—Å—Ç–∞–ª|—Ç–æ—Å–∫–∞|–ø–µ—á–∞–ª—å|—Å–ª–æ–∂–Ω–æ)", text):
            return "supportive"      # –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–∏–π
        if re.search(r"(–≤–µ—Å–µ–ª|—É—Ä–∞|—Å–º–µ—à–Ω|—Ö–∞—Ö–∞|—Ä–∞–¥|–∫–ª–∞—Å—Å|—Å—É–ø–µ—Ä)", text):
            return "cheerful"        # –≤–µ—Å—ë–ª—ã–π
        if re.search(r"(–∑–ª—é—Å—å|—Ä–∞–∑–¥—Ä–∞–∂|–±–µ—Å–∏—Ç|–Ω–µ–Ω–∞–≤–∏–∂—É|–∑–ª–æ–π)", text):
            return "calm"            # —Å–ø–æ–∫–æ–π–Ω—ã–π (—É—Å–ø–æ–∫–∞–∏–≤–∞—é—â–∏–π)
        if re.search(r"(–ª—é–±–ª—é|—Å–ø–∞—Å–∏–±–æ|–±–ª–∞–≥–æ–¥–∞—Ä—é|–±–ª–∞–≥–æ–¥–∞—Ä–µ–Ω)", text):
            return "empathetic"      # —ç–º–ø–∞—Ç–∏—á–Ω—ã–π
        return None

    def _detect_tone(self, user_text: str, reply: str) -> Optional[str]:
        text = f"{user_text} {reply}".lower()
        if re.search(r"(–∫–æ—Ä–æ—Ç–∫–æ|–ø–æ –¥–µ–ª—É|–±–µ–∑ –≤–æ–¥—ã|–Ω–µ —Ä–∞—Å—Ç—è–≥–∏–≤–∞–π)", text):
            return "concise"
        if re.search(r"(—Ä–∞—Å—Å–∫–∞–∂–∏ –ø–æ–¥—Ä–æ–±–Ω–µ–µ|–æ–±—ä—è—Å–Ω–∏|–ø–æ—è—Å–Ω–∏|—Ä–∞–∑–≤–µ—Ä–Ω—É—Ç–æ)", text):
            return "detailed"
        if re.search(r"(—à—É—Ç–∏|–∞–Ω–µ–∫–¥–æ—Ç|—Å–º–µ—à–Ω|–∏–≥—Ä–∏–≤–æ)", text):
            return "playful"
        if re.search(r"(–º–µ–¥–ª–µ–Ω–Ω–æ|—Å–ø–æ–∫–æ–π–Ω–æ|—Ç–∏—à–µ|–Ω–µ —Å–ø–µ—à–∏)", text):
            return "calm"
        return None

    def _detect_style(self, user_text: str, reply: str) -> Optional[str]:
        text = f"{user_text} {reply}".lower()
        if re.search(r"(—Å–ø–∏—Å–∫–æ–º|–±—É–ª–ª–µ—Ç—ã|–±—É–ª–ª–µ—Ç–∞–º–∏|–ø–æ –ø—É–Ω–∫—Ç–∞–º)", text):
            return "bulleted"
        if re.search(r"(–ø—Ä–∏–º–µ—Ä|–ø—Ä–∏–º–µ—Ä–æ–º|–∞–Ω–∞–ª–æ–≥–∏—è|—Å—Ä–∞–≤–Ω–µ–Ω–∏–µ)", text):
            return "with_examples"
        return None


# ======================================================================
#                       –û–°–ù–û–í–ù–û–ô –ö–õ–ê–°–° –°–ò–°–¢–ï–ú–´
# ======================================================================
class RealtimeVTuberSystem:
    def __init__(
        self,
        config: Optional[VTuberConfig] = None,
        enable_unity: bool = True,
        install_signal_handlers: bool = True,
    ):
        """–û—Å–Ω–æ–≤–Ω–æ–π –∫–æ–Ω—Ç—Ä–æ–ª–ª–µ—Ä VTuber-—Å–∏—Å—Ç–µ–º—ã.
        install_signal_handlers ‚Äî –µ—Å–ª–∏ False, –Ω–µ –±—É–¥–µ—Ç –ª–æ–≤–∏—Ç—å Ctrl+C (–¥–ª—è Unity, —Ç–µ—Å—Ç–æ–≤ –∏ Jupyter).
        """
        # --- –ê–≤—Ç–æ–æ—Ç–∫–ª—é—á–µ–Ω–∏–µ —Å–∏–≥–Ω–∞–ª–æ–≤, –µ—Å–ª–∏ —Å—Ä–µ–¥–∞ –Ω–µ —Ç–µ—Ä–º–∏–Ω–∞–ª—å–Ω–∞—è ---
        if not sys.stdout.isatty():
            install_signal_handlers = False

        self.config = config or VTuberConfig()
        self.mood = MoodManager()
        self.memory: Optional[HybridMemory] = None
        self.personalization = PersonalizationManager()
        self.install_signal_handlers = install_signal_handlers

        # ‚úÖ –¥–æ–±–∞–≤–ª–µ–Ω–æ: –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–≥–æ –ø–æ–≤–µ–¥–µ–Ω–∏—è
        self.adaptive = AdaptivePersonality(self.personalization)

        # --- –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤ –¥–ª—è STT/TTS (—á–µ—Ä–µ–∑ config.json —Å fallback) ---
        self.stt_device = "cpu"
        self.tts_device = "cpu"
        try:
            import torch
            try:
                # —á–∏—Ç–∞–µ–º –∫–æ–Ω—Ñ–∏–≥ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω–æ (–µ—Å–ª–∏ –∑–∞–¥–∞–Ω–æ)
                cfg = load_config()
                devices_cfg = cfg.get("devices", {})
            except Exception:
                devices_cfg = {}

            stt_device = devices_cfg.get("stt") or devices_cfg.get("audio")
            tts_device = devices_cfg.get("tts") or devices_cfg.get("audio")

            # –µ—Å–ª–∏ –≤ –∫–æ–Ω—Ñ–∏–≥–µ –Ω–µ —É–∫–∞–∑–∞–Ω–æ ‚Äî –∞–≤—Ç–æ–¥–µ—Ç–µ–∫—Ç
            if not stt_device or not tts_device:
                if torch.cuda.is_available():
                    gpu_count = torch.cuda.device_count()
                    logger.info(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ GPU: {gpu_count} —à—Ç.")
                    stt_device = stt_device or "cuda:0"
                    tts_device = tts_device or ("cuda:1" if gpu_count > 1 else "cuda:0")
                else:
                    logger.warning("CUDA –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º CPU")
                    stt_device = "cpu"
                    tts_device = "cpu"
            else:
                logger.info(f"–ó–∞–¥–∞–Ω–æ –≤ –∫–æ–Ω—Ñ–∏–≥–µ: STT={stt_device}, TTS={tts_device}")
        except ImportError:
            logger.warning("PyTorch –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º CPU")
            stt_device = "cpu"
            tts_device = "cpu"

        self.stt_device = stt_device
        self.tts_device = tts_device

        # --- –ú–æ–∑–≥ (LLM —Ä–æ—É—Ç–µ—Ä) ---
        try:
            ollama_client = OptimizedOllamaClient()
            self.ollama_client = ollama_client
            self.router = HybridOllamaRouter(
                ollama=ollama_client,
                fast_model=self.config.fast_model,
                smart_model=self.config.smart_model,
            )
            logger.info(f"Router –≥–æ—Ç–æ–≤: fast={self.config.fast_model}, smart={self.config.smart_model}")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ LLM —Ä–æ—É—Ç–µ—Ä–∞: {e}", exc_info=True)
            raise RuntimeError("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å LLM —Å–∏—Å—Ç–µ–º—É") from e

        # --- –ê—É–¥–∏–æ ---
        try:
            self.tts = TTS(
                model="cosyvoice-2",
                speaker="female",
                style="soft",
                language="ru",
                device=self.tts_device,
            )
            cfg = {}
            try:
                cfg = load_config()
            except Exception:
                cfg = {}
            stt_cfg = cfg.get("stt", {})
            self.stt = WhisperSTT(
                model_size=stt_cfg.get("model_size", "small"),
                device=self.stt_device,
                compute_type=stt_cfg.get("compute_type", "float16"),
                beam_size=stt_cfg.get("beam_size", 1),
                sample_rate=stt_cfg.get("sample_rate", 16000),
                chunk_sec=stt_cfg.get("chunk_sec", 0.5),
                vad_backend=stt_cfg.get("vad_backend", "silero_onnx"),
                silero_model_path=stt_cfg.get("silero_model_path"),
                speech_threshold=stt_cfg.get("speech_threshold", 0.55),
                silence_threshold=stt_cfg.get("silence_threshold", 0.45),
                min_speech_ms=stt_cfg.get("min_speech_ms", 200),
                min_silence_ms=stt_cfg.get("min_silence_ms", 500),
            )
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∞—É–¥–∏–æ –º–æ–¥—É–ª–µ–π: {e}", exc_info=True)
            raise RuntimeError("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∞—É–¥–∏–æ –ø–æ–¥—Å–∏—Å—Ç–µ–º—É") from e

        # --- –ê–≤–∞—Ç–∞—Ä (OSC) ---
        self.avatar = MultiTargetOSCController(enable_unity=enable_unity)

        # --- –°–ª—É–∂–µ–±–Ω—ã–µ —Ñ–ª–∞–≥–∏ ---
        self._running = False
        self._stop_lock = asyncio.Lock()
        self._signal_handlers_installed = False

        logger.info(f"‚úÖ RealtimeVTuberSystem –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ (STT: {self.stt_device}, TTS: {self.tts_device})")

    # ------------------------------------------------------------------
    async def start(self) -> None:
        if self._running:
            logger.warning("VTuber —É–∂–µ –∑–∞–ø—É—â–µ–Ω.")
            return

        self.memory = HybridMemory()
        await self.memory.aopen()
        self._running = True

        # --- –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤ —Å–∏–≥–Ω–∞–ª–æ–≤ ---
        if self.install_signal_handlers and not self._signal_handlers_installed:
            loop = asyncio.get_running_loop()

            def _graceful_stop(sig: signal.Signals):
                logger.warning(f"–ü–æ–ª—É—á–µ–Ω —Å–∏–≥–Ω–∞–ª {sig.name} ‚Äî –Ω–∞—á–∏–Ω–∞–µ–º –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ...")
                asyncio.create_task(self.stop())

            # Windows-compatible signal handling
            if platform.system() != "Windows":
                # Unix-like systems
                for sig in (signal.SIGINT, signal.SIGTERM):
                    with contextlib.suppress(NotImplementedError):
                        loop.add_signal_handler(sig, functools.partial(_graceful_stop, sig))
            else:
                # Windows fallback
                def windows_handler(signum, frame):
                    asyncio.create_task(self.stop())
                signal.signal(signal.SIGINT, windows_handler)

            self._signal_handlers_installed = True

        logger.info("VTuber –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ (–Ω–∞–∂–º–∏ Ctrl+C –¥–ª—è –≤—ã—Ö–æ–¥–∞).")

    # ------------------------------------------------------------------
    async def stop(self) -> None:
        async with self._stop_lock:
            if not self._running:
                return
            self._running = False

            logger.info("–û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º VTuber...")

            with contextlib.suppress(Exception):
                await self.tts.stop()
            with contextlib.suppress(Exception):
                await self.avatar.shutdown()
            with contextlib.suppress(Exception):
                if self.memory:
                    await self.memory.aclose()
            with contextlib.suppress(Exception):
                if getattr(self, 'ollama_client', None):
                    await self.ollama_client.close()

            logger.info("VTuber –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –∑–∞–≤–µ—Ä—à—ë–Ω.")

    # ------------------------------------------------------------------
    async def run_dialogue(self) -> None:
        """–û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –¥–∏–∞–ª–æ–≥–∞ —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
        if not self._running:
            logger.error("–°–∏—Å—Ç–µ–º–∞ –Ω–µ –∑–∞–ø—É—â–µ–Ω–∞. –°–Ω–∞—á–∞–ª–∞ –≤—ã–∑–æ–≤–∏ await start().")
            return
        
        error_count = 0
        consecutive_empty_responses = 0
        
        while self._running:
            user_text = None
            reply = None
            context = None
            
            try:
                # === 1. STT —Å —Ç–∞–π–º–∞—É—Ç–æ–º ===
                try:
                    user_text = await asyncio.wait_for(
                        self.stt.listen(), 
                        timeout=30.0
                    )
                except asyncio.TimeoutError:
                    logger.warning("‚è±Ô∏è STT timeout - –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –º–æ–ª—á–∏—Ç")
                    await asyncio.sleep(0.5)
                    continue
                
                if not user_text or not user_text.strip():
                    await asyncio.sleep(0.2)
                    continue
                
                # === 2. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏ –ø–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ ===
                await self.memory.add_turn("user", user_text)
                
                # üîß –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø: –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
                context = await self.memory.context(
                    last_n_turns=10,  # –≤–º–µ—Å—Ç–æ 20
                    max_facts=30      # –≤–º–µ—Å—Ç–æ 100
                )
                
                # === 3. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ ===
                base_prompt = "–¢—ã ‚Äî –≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã–π VTuber-–∫–æ–º–ø–∞–Ω—å–æ–Ω. –û–±—â–∞–π—Å—è –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ –∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–π –∫–æ–Ω—Ç–∞–∫—Ç."
                personalized_prompt = await apply_personalized_prompt(
                    base_prompt, 
                    username="guest", 
                    platform="voice"
                )
                
                reply, emotion_name = await self.router.generate_reply(
                    user_text, 
                    context=context, 
                    system_prompt=personalized_prompt
                )
                
                # === 4. –í–∞–ª–∏–¥–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ ===
                if not reply or not reply.strip():
                    consecutive_empty_responses += 1
                    logger.warning(
                        f"‚ö†Ô∏è LLM –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç ({consecutive_empty_responses}/3)"
                    )
                    
                    if consecutive_empty_responses >= 3:
                        logger.error("‚ùå LLM –Ω–µ –æ—Ç–≤–µ—á–∞–µ—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback")
                        reply = "–ò–∑–≤–∏–Ω–∏, —É –º–µ–Ω—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã. –ü–æ–ø—Ä–æ–±—É–π –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å."
                        emotion_name = "neutral"
                        consecutive_empty_responses = 0
                    else:
                        await asyncio.sleep(1)
                        continue
                else:
                    consecutive_empty_responses = 0
                
                # === 5. –í–∞–ª–∏–¥–∞—Ü–∏—è —ç–º–æ—Ü–∏–∏ ===
                VALID_EMOTIONS = {"happy", "sad", "angry", "surprised", "neutral", "joy"}
                if not emotion_name or emotion_name.lower() not in VALID_EMOTIONS:
                    logger.warning(f"‚ö†Ô∏è –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è —ç–º–æ—Ü–∏—è '{emotion_name}', –∏—Å–ø–æ–ª—å–∑—É–µ–º neutral")
                    emotion_name = "neutral"
                
                # === 6. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ ===
                await self.memory.add_turn("assistant", reply)
                
                # === 7. –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π –∑–∞–ø—É—Å–∫ TTS –∏ –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ ===
                # üöÄ –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø: TTS –∏–¥—ë—Ç —Å—Ä–∞–∑—É, –∞–¥–∞–ø—Ç–∞—Ü–∏—è –≤ —Ñ–æ–Ω–µ
                tts_task = asyncio.create_task(
                    self.tts.speak(reply, emotion=emotion_name)
                )
                
                # –§–æ–Ω–æ–≤—ã–µ –∑–∞–¥–∞—á–∏ (–Ω–µ –±–ª–æ–∫–∏—Ä—É—é—Ç –æ—Ç–≤–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é)
                asyncio.create_task(
                    self.adaptive.analyze_and_update(user_text, reply)
                )
                asyncio.create_task(
                    log_after_dialog("guest", user_text, reply, emotion_name)
                )
                
                # –ñ–¥—ë–º —Ç–æ–ª—å–∫–æ TTS (–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–ª—ã—à–∏—Ç –æ—Ç–≤–µ—Ç –±—ã—Å—Ç—Ä–µ–µ!)
                await tts_task
                
                # === 8. –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∞–≤–∞—Ç–∞—Ä–æ–º ===
                if hasattr(self.avatar, "set_emotion"):
                    try:
                        await self.avatar.set_emotion(emotion_name)
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ —ç–º–æ—Ü–∏–∏ –∞–≤–∞—Ç–∞—Ä–∞: {e}")
                
                # –£—Å–ø–µ—Ö - —Å–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—á—ë—Ç—á–∏–∫ –æ—à–∏–±–æ–∫
                error_count = 0
                
            except asyncio.CancelledError:
                logger.info("üõë –î–∏–∞–ª–æ–≥ –æ—Ç–º–µ–Ω—ë–Ω (CancelledError)")
                break
                
            except sd.PortAudioError as e:
                error_count += 1
                logger.error(f"üé§ –ê—É–¥–∏–æ-–æ—à–∏–±–∫–∞ ({error_count}/5): {e}")
                
                if error_count >= 5:
                    logger.error("‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –∞—É–¥–∏–æ, –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫ STT...")
                    try:
                        await self.stt.stop() if hasattr(self.stt, 'stop') else None
                        await asyncio.sleep(2)
                    except Exception:
                        pass
                    error_count = 0
                    await asyncio.sleep(3)
                else:
                    await asyncio.sleep(1)
                    
            except Exception as e:
                error_count += 1
                logger.exception(f"‚ùå –û—à–∏–±–∫–∞ –≤ —Ü–∏–∫–ª–µ –¥–∏–∞–ª–æ–≥–∞ ({error_count}/5): {e}")
                
                if error_count >= 5:
                    logger.error("‚ùå –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –æ—à–∏–±–æ–∫, –ø–∞—É–∑–∞ 5 —Å–µ–∫—É–Ω–¥...")
                    await asyncio.sleep(5)
                    error_count = 0
                else:
                    await asyncio.sleep(1)
            
            finally:
                # === 9. –û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏ ===
                del user_text, reply, context
                # –î–∞—ë–º —Å–±–æ—Ä—â–∏–∫—É –º—É—Å–æ—Ä–∞ –≤—Ä–µ–º—è
                if error_count == 0:
                    await asyncio.sleep(0.1)
        
        logger.info("‚úÖ –í—ã—Ö–æ–¥ –∏–∑ —Ü–∏–∫–ª–∞ –¥–∏–∞–ª–æ–≥–∞")


# ======================================================================
# –¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞ (—Ä—É—á–Ω–æ–π –∑–∞–ø—É—Å–∫)
# ======================================================================
if __name__ == "__main__":
    async def main():
        vtuber = RealtimeVTuberSystem()
        await vtuber.start()
        try:
            await vtuber.run_dialogue()
        finally:
            await vtuber.stop()

    asyncio.run(main())
